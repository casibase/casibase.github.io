"use strict";(self.webpackChunkcasibase_website=self.webpackChunkcasibase_website||[]).push([[5283],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>m});var r=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function s(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function a(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?s(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):s(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,i=function(e,t){if(null==e)return{};var n,r,i={},s=Object.keys(e);for(r=0;r<s.length;r++)n=s[r],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(r=0;r<s.length;r++)n=s[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var d=r.createContext({}),o=function(e){var t=r.useContext(d),n=t;return e&&(n="function"==typeof e?e(t):a(a({},t),e)),n},u=function(e){var t=o(e.components);return r.createElement(d.Provider,{value:t},e.children)},g="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},h=r.forwardRef((function(e,t){var n=e.components,i=e.mdxType,s=e.originalType,d=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),g=o(n),h=i,m=g["".concat(d,".").concat(h)]||g[h]||c[h]||s;return n?r.createElement(m,a(a({ref:t},u),{},{components:n})):r.createElement(m,a({ref:t},u))}));function m(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var s=n.length,a=new Array(s);a[0]=h;var l={};for(var d in t)hasOwnProperty.call(t,d)&&(l[d]=t[d]);l.originalType=e,l[g]="string"==typeof e?e:i,a[1]=l;for(var o=2;o<s;o++)a[o]=n[o];return r.createElement.apply(null,a)}return r.createElement.apply(null,n)}h.displayName="MDXCreateElement"},83:(e,t,n)=>{n.d(t,{Z:()=>i});var r=n(7294);function i(e){return r.createElement("iframe",{src:e.src,width:e.width,height:e.height,style:{borderRadius:"20px"},frameBorder:"0",scrolling:"no"})}i.defaultProps={src:"https://ai.casibase.com",width:"600",height:"700"}},7390:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>a,default:()=>c,frontMatter:()=>s,metadata:()=>l,toc:()=>o});var r=n(7462),i=(n(7294),n(3905));n(5758),n(83);const s={title:"\xdcbersicht",description:"\xdcbersicht der Text Splitter",keywords:["Casibase","Text-Teiler"],authors:["IsAurora6"]},a=void 0,l={unversionedId:"textsplitters/overview",id:"textsplitters/overview",title:"\xdcbersicht",description:"\xdcbersicht der Text Splitter",source:"@site/i18n/de/docusaurus-plugin-content-docs/current/textsplitters/overview.mdx",sourceDirName:"textsplitters",slug:"/textsplitters/overview",permalink:"/de/docs/textsplitters/overview",draft:!1,editUrl:"https://github.com/casibase/casibase-website/edit/master/docs/textsplitters/overview.mdx",tags:[],version:"current",frontMatter:{title:"\xdcbersicht",description:"\xdcbersicht der Text Splitter",keywords:["Casibase","Text-Teiler"],authors:["IsAurora6"]},sidebar:"tutorialSidebar",previous:{title:"TextSplitters",permalink:"/de/docs/category/textsplitters"},next:{title:"Chats",permalink:"/de/docs/category/chats"}},d={},o=[{value:"Standard Text Splitter",id:"standard-text-splitter",level:2},{value:"Frage-Antwort-Splitter",id:"frage-antwort-splitter",level:2}],u={toc:o},g="wrapper";function c(e){let{components:t,...n}=e;return(0,i.kt)(g,(0,r.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Text Splitters")," sind ein entscheidender Bestandteil beim Aufbau von Anwendungen mit gro\xdfen Sprachmodellen (LLM). Ihre Hauptaufgabe besteht darin, lange Texte in mehrere k\xfcrzere Abschnitte zu unterteilen, was nachfolgende Aufgaben wie Text-Einbettungen, retrieval-augmented generation (RAG) und Frage-Antwort-Systeme erleichtert."),(0,i.kt)("p",null,"Bei LLMs wird die Textaufteilung aus mehreren Hauptgr\xfcnden vorgenommen:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Optimierung von Effizienz und Genauigkeit: Durch das Aufteilen gro\xdfer Textbl\xf6cke in kleinere Abschnitte kann die Relevanz und Genauigkeit der vom LLM erzeugten Einbettungen optimiert werden. Chunking hilft dabei sicherzustellen, dass der eingebettete Inhalt minimale St\xf6rungen enth\xe4lt und gleichzeitig semantische Relevanz beibeh\xe4lt. Beispielsweise enth\xe4lt bei der semantischen Suche, wenn ein Dokumentenkorpus indexiert wird, jedes Dokument wertvolle Informationen zu bestimmten Themen. Die Anwendung einer effektiven Chunking-Strategie stellt sicher, dass die Suchergebnisse den Kern der Nutzeranfrage genau erfassen."),(0,i.kt)("li",{parentName:"ul"},"Begrenzung der Kontextfenstergr\xf6\xdfe: Bei der Verwendung von Modellen wie GPT-4 gibt es eine Grenze f\xfcr die Anzahl der verarbeitbaren Tokens. Zum Beispiel hat GPT-4 eine Kontextfenstergr\xf6\xdfenbegrenzung von 32K Tokens. Obwohl dieses Limit im Allgemeinen kein Problem darstellt, ist es von Anfang an wichtig, die Chunkgr\xf6\xdfe zu ber\xfccksichtigen. Wenn die Text-Chunks zu gro\xdf sind, k\xf6nnten Informationen verloren gehen oder nicht alle Inhalte im Kontext eingebettet werden, was die Leistung und Ausgabe des Modells beeintr\xe4chtigen kann."),(0,i.kt)("li",{parentName:"ul"},"Umgang mit langen Dokumenten: Obwohl Einbettungsvektoren f\xfcr lange Dokumente den Gesamtkontext erfassen k\xf6nnen, \xfcbersehen sie m\xf6glicherweise wichtige Details zu spezifischen Themen, was zu ungenauen oder unvollst\xe4ndigen Ergebnissen f\xfchren kann. Chunking erm\xf6glicht eine bessere Kontrolle \xfcber die Extraktion und Einbettung von Informationen und reduziert so das Risiko des Informationsverlusts.")),(0,i.kt)("p",null,"Casibase bietet zur Zeit mehrere Aufteilungsmethoden an, die es dem Anwender erm\xf6glichen, unterschiedliche Verarbeitungsstrategien f\xfcr verschiedene Textszenarien anzuwenden."),(0,i.kt)("h2",{id:"standard-text-splitter"},"Standard Text Splitter"),(0,i.kt)("p",null,"Der Standard Text Splitter ist darauf ausgelegt, Texte effizient basierend auf der Tokenanzahl und der Textstruktur zu segmentieren. Seine Aufteilungsstrategie umfasst:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Zeilenlesung und Absatzerkennung: Der Text wird Zeile f\xfcr Zeile gelesen, mit aufeinanderfolgenden Leerzeilen zur genauen Bestimmung von Absatzbr\xfcchen verwendet. Dar\xfcber hinaus werden nat\xfcrliche Durchbr\xfcche durch Markierungen sensibel identifiziert, wodurch eine logische und pr\xe4zise Textsegmentierung gew\xe4hrleistet wird."),(0,i.kt)("li",{parentName:"ul"},"Spezielle Behandlung f\xfcr Code-Bl\xf6cke: Codebl\xf6cke mit ","`","`","`"," Symbolen werden separat behandelt. Die Anzahl der Zeilen innerhalb eines Codeblocks bestimmt, ob er als Segment allein stehen kann. Dieser Mechanismus bewahrt die Integrit\xe4t von Code-Bl\xf6cken, w\xe4hrend effektiv verhindert wird, dass einzelne Textsegmente die Tokengrenze \xfcberschreiten."),(0,i.kt)("li",{parentName:"ul"},"Beibehaltung der Sentenz-Integrit\xe4t: W\xe4hrend des gesamten Teilungsprozesses wird die strikte Einhaltung der Satzintegrit\xe4t gewahrt, wodurch sichergestellt wird, dass die S\xe4tze nie geteilt werden. Diese Funktion garantiert, dass jedes Textsegment eine vollst\xe4ndige Informationseinheit enth\xe4lt. Unabh\xe4ngig von der Komplexit\xe4t des Textes erfolgt die Segmentierung an Satzgrenzen genau, wodurch Unklarheiten und Informationsverluste durch gebrochene Strafen vermieden werden.")),(0,i.kt)("h2",{id:"frage-antwort-splitter"},"Frage-Antwort-Splitter"),(0,i.kt)("p",null,"Der Frage-Antwort-Splitter konzentriert sich auf die pr\\u00e4zise Segmentierung von Frage-Antwort-formatierten Texten und bietet die folgenden wesentlichen Vorteile:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},'Pr\\u00e4zises Aufteilen von Frage-Antwort-Einheiten: Es wird ein zeilenweises Scanverfahren verwendet, um die Struktur von Frage-Antwort-Texten intelligent zu erkennen. Durch die Bestimmung, ob jede Zeile mit "Q:" oder "A:" beginnt, werden die Grenzen zwischen Fragen und Antworten pr\\u00e4zise festgestellt, sodass jedes Frage-Antwort-Paar vollst\xe4ndig segmentiert wird. Dies garantiert die Unabh\xe4ngigkeit und Vollst\xe4ndigkeit jeder Frage- und Frageeinheit und bietet saubere Daten f\xfcr die nachfolgende Verarbeitung und Auswertung.'),(0,i.kt)("li",{parentName:"ul"},"Klare und logische Implementierung: Der Code ist einfach und intuitiv, so dass er leicht zu verstehen und zu warten ist. Durch die Verwaltung des Zustands des aktuellen Frage-Antwort-Paares und einer Kennzeichnung, die angibt, ob eine Antwort gesammelt wird, wird der Textsegmentierungsprozess klar gesteuert, wodurch die korrekte Paarung jeder Frage-Antwort-Einheit sichergestellt wird.")))}c.isMDXComponent=!0},5758:(e,t,n)=>{n.d(t,{Z:()=>r});const r={gradientborder:"gradientborder_ztcL"}}}]);