"use strict";(self.webpackChunkcasibase_website=self.webpackChunkcasibase_website||[]).push([[2682],{3905:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>g});var r=t(7294);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function s(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function a(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?s(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):s(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function o(e,n){if(null==e)return{};var t,r,i=function(e,n){if(null==e)return{};var t,r,i={},s=Object.keys(e);for(r=0;r<s.length;r++)t=s[r],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(r=0;r<s.length;r++)t=s[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var l=r.createContext({}),u=function(e){var n=r.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):a(a({},n),e)),t},c=function(e){var n=u(e.components);return r.createElement(l.Provider,{value:n},e.children)},d="mdxType",h={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},p=r.forwardRef((function(e,n){var t=e.components,i=e.mdxType,s=e.originalType,l=e.parentName,c=o(e,["components","mdxType","originalType","parentName"]),d=u(t),p=i,g=d["".concat(l,".").concat(p)]||d[p]||h[p]||s;return t?r.createElement(g,a(a({ref:n},c),{},{components:t})):r.createElement(g,a({ref:n},c))}));function g(e,n){var t=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var s=t.length,a=new Array(s);a[0]=p;var o={};for(var l in n)hasOwnProperty.call(n,l)&&(o[l]=n[l]);o.originalType=e,o[d]="string"==typeof e?e:i,a[1]=o;for(var u=2;u<s;u++)a[u]=t[u];return r.createElement.apply(null,a)}return r.createElement.apply(null,t)}p.displayName="MDXCreateElement"},83:(e,n,t)=>{t.d(n,{Z:()=>i});var r=t(7294);function i(e){return r.createElement("iframe",{src:e.src,width:e.width,height:e.height,style:{borderRadius:"20px"},frameBorder:"0",scrolling:"no"})}i.defaultProps={src:"https://ai.casibase.com",width:"600",height:"700"}},1332:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>u});var r=t(7462),i=(t(7294),t(3905));t(5758),t(83);const s={title:"\xdcberblick",description:"Speicher-\xdcberblick",keywords:["Casibase","Speicher"],authors:["IsAurora6"]},a=void 0,o={unversionedId:"stores/overview",id:"stores/overview",title:"\xdcberblick",description:"Speicher-\xdcberblick",source:"@site/i18n/de/docusaurus-plugin-content-docs/current/stores/overview.mdx",sourceDirName:"stores",slug:"/stores/overview",permalink:"/de/docs/stores/overview",draft:!1,editUrl:"https://github.com/casibase/casibase-website/edit/master/docs/stores/overview.mdx",tags:[],version:"current",frontMatter:{title:"\xdcberblick",description:"Speicher-\xdcberblick",keywords:["Casibase","Speicher"],authors:["IsAurora6"]},sidebar:"tutorialSidebar",previous:{title:"Stores",permalink:"/de/docs/category/stores"},next:{title:"Speicherkonfiguration",permalink:"/de/docs/stores/store-configuration"}},l={},u=[{value:"Erster Eintrag \xdcberblick \xfcber die Speicherfunktion",id:"erster-eintrag-\xfcberblick-\xfcber-die-speicherfunktion",level:2},{value:"2. Vorteile des Speichers",id:"2-vorteile-des-speichers",level:2},{value:"2.1 Multi-Modell-Integration",id:"21-multi-modell-integration",level:3},{value:"2.2 Vielf\xe4ltige Speicher- und Embedding-Optionen",id:"22-vielf\xe4ltige-speicher--und-embedding-optionen",level:3},{value:"2.3 Multi-Speicher-Modus",id:"23-multi-speicher-modus",level:3},{value:"2.4 Cross-Store Vector Sharing",id:"24-cross-store-vector-sharing",level:3},{value:"2.5 Streamlined Management",id:"25-streamlined-management",level:3},{value:"3. Zusammenfassung",id:"3-zusammenfassung",level:2}],c={toc:u},d="wrapper";function h(e){let{components:n,...t}=e;return(0,i.kt)(d,(0,r.Z)({},c,t,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("h2",{id:"erster-eintrag-\xfcberblick-\xfcber-die-speicherfunktion"},"Erster Eintrag \xdcberblick \xfcber die Speicherfunktion"),(0,i.kt)("p",null,"In Casibase ist die Speicherfunktion eines der Kernmodule. Sie erm\xf6glicht Benutzern, Speicher-, Modellierungs- und Embedding-Dienstleister f\xfcr die Wissensdatenbankspeicherung, Textvektortransformation und Interaktion mit Chatbots zu integrieren. Durch die Speicherfunktion k\xf6nnen Benutzer ein effizientes, flexibles und leistungsstarkes KI-Wissensmanagementsystem aufbauen."),(0,i.kt)("h2",{id:"2-vorteile-des-speichers"},"2. Vorteile des Speichers"),(0,i.kt)("h3",{id:"21-multi-modell-integration"},"2.1 Multi-Modell-Integration"),(0,i.kt)("p",null,"Die Speicherfunktion von Casibase unterst\xfctzt mehrere g\xe4ngige KI-Sprachmodelle, einschlie\xdflich OpenAI (wie GPT-3.5, GPT-4), Azure OpenAI, HuggingFace, Google Gemini und mehr. Diese Multi-Modell-Unterst\xfctzung erm\xf6glicht es Benutzern, das am besten geeignete KI-Modell basierend auf ihren spezifischen Anforderungen auszuw\xe4hlen und eine Balance zwischen Leistung, Kosten und Funktionalit\xe4t zu finden."),(0,i.kt)("h3",{id:"22-vielf\xe4ltige-speicher--und-embedding-optionen"},"2.2 Vielf\xe4ltige Speicher- und Embedding-Optionen"),(0,i.kt)("p",null,"Benutzer k\xf6nnen frei Speicher- und Embedding-Dienstleister w\xe4hlen, um verschiedenen Datenspeicher- und Verarbeitungsanforderungen gerecht zu werden. Diese Flexibilit\xe4t erm\xf6glicht es Benutzern, die am besten geeigneten Speicher- und Embedding-L\xf6sungen basierend auf ihrem technischen Stack und ihren gesch\xe4ftlichen Anforderungen zu konfigurieren."),(0,i.kt)("h3",{id:"23-multi-speicher-modus"},"2.3 Multi-Speicher-Modus"),(0,i.kt)("p",null,"Casibase unterst\xfctzt einen Multi-Speicher-Modus, der es Benutzern erm\xf6glicht, verschiedene Modelle, Speicher- und Embedding-Dienste in verschiedenen Speichern zu verwenden, um ma\xdfgeschneiderte Dienste f\xfcr verschiedene Szenarien und Benutzer anzubieten. Diese Funktion erm\xf6glicht es Benutzern, Speicher basierend auf unterschiedlichen Gesch\xe4ftsanforderungen flexibel zu konfigurieren und zu wechseln."),(0,i.kt)("h3",{id:"24-cross-store-vector-sharing"},"2.4 Cross-Store Vector Sharing"),(0,i.kt)("p",null,"Stores in Casibase can be configured to use vectors from other stores through the ",(0,i.kt)("strong",{parentName:"p"},"Vector stores")," field. This allows you to create a main store that searches across multiple specialized knowledge bases, or let different stores share their knowledge with each other. Instead of duplicating content, stores can dynamically access relevant information from other stores while maintaining their own separate vector databases."),(0,i.kt)("h3",{id:"25-streamlined-management"},"2.5 Streamlined Management"),(0,i.kt)("p",null,'The interface adapts to how you work. File-focused workflows can use the "Hide chat" toggle to clear away AI provider columns from the store list. Each store can also include example questions that appear when users start chatting, helping them understand what to ask without reading documentation.'),(0,i.kt)("h2",{id:"3-zusammenfassung"},"3. Zusammenfassung"),(0,i.kt)("p",null,"Die Speicherfunktion von Casibase bietet Benutzern ein leistungsstarkes Wissensmanagementsystem durch die Integration mehrerer KI-Modelle, Speicher- und Embedding-Dienste, sodass sie Wissensdatenbanken flexibel aufbauen und verwalten k\xf6nnen. Der Multi-Speicher-Modus und die Unternehmensfunktionen verbessern weiter die Flexibilit\xe4t und Sicherheit des Systems, wodurch es f\xfcr verschiedene Anwendungsszenarien geeignet ist."),(0,i.kt)("p",null,"Casibase ist ein Open-Source-KI-Wissensdatenbanksystem, das darauf abzielt, Unternehmen effiziente und flexible L\xf6sungen f\xfcr Wissensmanagement und Dialoge zu bieten. Provider werden in drei Hauptkategorien unterteilt: Modellanbieter, Embedding-Anbieter und Speicheranbieter, die jeweils f\xfcr die Verarbeitung von KI-Modellen und Datenspeicherung verantwortlich sind."))}h.isMDXComponent=!0},5758:(e,n,t)=>{t.d(n,{Z:()=>r});const r={gradientborder:"gradientborder_ztcL"}}}]);