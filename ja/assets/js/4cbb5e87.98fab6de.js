"use strict";(self.webpackChunkcasibase_website=self.webpackChunkcasibase_website||[]).push([[4538],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>g});var i=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,i,r=function(e,t){if(null==e)return{};var n,i,r={},a=Object.keys(e);for(i=0;i<a.length;i++)n=a[i],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(i=0;i<a.length;i++)n=a[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=i.createContext({}),c=function(e){var t=i.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},u=function(e){var t=c(e.components);return i.createElement(l.Provider,{value:t},e.children)},p="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},m=i.forwardRef((function(e,t){var n=e.components,r=e.mdxType,a=e.originalType,l=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),p=c(n),m=r,g=p["".concat(l,".").concat(m)]||p[m]||d[m]||a;return n?i.createElement(g,s(s({ref:t},u),{},{components:n})):i.createElement(g,s({ref:t},u))}));function g(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=n.length,s=new Array(a);s[0]=m;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o[p]="string"==typeof e?e:r,s[1]=o;for(var c=2;c<a;c++)s[c]=n[c];return i.createElement.apply(null,s)}return i.createElement.apply(null,n)}m.displayName="MDXCreateElement"},83:(e,t,n)=>{n.d(t,{Z:()=>r});var i=n(7294);function r(e){return i.createElement("iframe",{src:e.src,width:e.width,height:e.height,style:{borderRadius:"20px"},frameBorder:"0",scrolling:"no"})}r.defaultProps={src:"https://ai.casibase.com",width:"600",height:"700"}},6378:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>a,metadata:()=>o,toc:()=>c});var i=n(7462),r=(n(7294),n(3905));n(707),n(83);const a={title:"Overview",description:"Text Splitters Overview",keywords:["Casibase","Text Splitter"],authors:["IsAurora6"]},s=void 0,o={unversionedId:"textsplitters/overview",id:"textsplitters/overview",title:"Overview",description:"Text Splitters Overview",source:"@site/i18n/ja/docusaurus-plugin-content-docs/current/textsplitters/overview.mdx",sourceDirName:"textsplitters",slug:"/textsplitters/overview",permalink:"/ja/docs/textsplitters/overview",draft:!1,editUrl:"https://github.com/casibase/casibase-website/edit/master/docs/textsplitters/overview.mdx",tags:[],version:"current",frontMatter:{title:"Overview",description:"Text Splitters Overview",keywords:["Casibase","Text Splitter"],authors:["IsAurora6"]},sidebar:"tutorialSidebar",previous:{title:"TextSplitters",permalink:"/ja/docs/category/textsplitters"},next:{title:"Chats",permalink:"/ja/docs/category/chats"}},l={},c=[{value:"Default Text Splitter",id:"default-text-splitter",level:2},{value:"Q&amp;A Splitter",id:"qa-splitter",level:2}],u={toc:c},p="wrapper";function d(e){let{components:t,...n}=e;return(0,r.kt)(p,(0,i.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Text Splitters")," are a crucial component in building large language model (LLM) applications. Their primary role is to break long texts into multiple shorter segments, which facilitates subsequent tasks such as text embeddings, retrieval-augmented generation (RAG), and question-answering systems."),(0,r.kt)("p",null,"In LLMs, text splitting is performed for several main reasons:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Optimizing Efficiency and Accuracy: By decomposing large blocks of text into smaller segments, the relevance and accuracy of the embeddings produced by the LLM can be optimized. Chunking helps ensure that the embedded content contains minimal noise while retaining semantic relevance. For instance, in semantic search, when indexing a document corpus, each document contains valuable information on specific topics. Applying an effective chunking strategy ensures that search results accurately capture the essence of a user's query."),(0,r.kt)("li",{parentName:"ul"},"Limiting the Context Window Size: When using models like GPT-4, there is a limit to the number of tokens that can be processed. For example, GPT-4 has a context window size limit of 32K tokens. While this limit is generally not an issue, it is important to consider chunk size from the beginning. If the text chunks are too large, information might be lost or not all content may be embedded in the context, which can affect the model\u2019s performance and output."),(0,r.kt)("li",{parentName:"ul"},"Handling Long Documents: While embedding vectors for long documents can capture the overall context, they might overlook important details pertaining to specific topics, leading to outputs that are either imprecise or incomplete. Chunking enables better control over the extraction and embedding of information, thereby reducing the risk of information loss.")),(0,r.kt)("p",null,"Casibase currently offers multiple splitting methods, allowing users to apply different processing strategies for various text scenarios."),(0,r.kt)("h2",{id:"default-text-splitter"},"Default Text Splitter"),(0,r.kt)("p",null,"The default text splitter is designed to efficiently segment text based on token count and textual structure. Its splitting strategy includes:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Line Reading and Paragraph Recognition: The text is read line by line, with consecutive blank lines used to accurately determine paragraph breaks. It also sensitively identifies natural breakpoints through markers, ensuring logical and precise text segmentation."),(0,r.kt)("li",{parentName:"ul"},"Special Handling for Code Blocks: Code blocks enclosed by ","`","`","`"," symbols are treated separately. The number of lines within a code block determines whether it can stand alone as a segment. This mechanism preserves the integrity of code blocks while effectively preventing any single text segment from exceeding the token limit."),(0,r.kt)("li",{parentName:"ul"},"Maintaining Sentence Integrity: Throughout the splitting process, strict adherence to sentence integrity is maintained, ensuring that sentences are never divided. This feature guarantees that each text segment contains a complete unit of information. Regardless of the complexity of the text, segmentation is accurately performed at sentence boundaries, effectively avoiding ambiguity and information loss due to broken sentences.")),(0,r.kt)("h2",{id:"qa-splitter"},"Q&A Splitter"),(0,r.kt)("p",null,"The Q&A splitter focuses on the precise segmentation of question-and-answer formatted texts and offers the following core advantages:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Accurate Splitting of Q&A Units: It uses a line-by-line scanning mechanism to intelligently identify the structure of Q&A texts. By determining whether each line begins with \u201cQ:\u201d or \u201cA:\u201d, it precisely locates the boundaries between questions and answers, ensuring that each Q&A pair is completely segmented. This guarantees the independence and completeness of each Q&A unit, providing clean data for subsequent Q&A processing and analysis."),(0,r.kt)("li",{parentName:"ul"},"Clear and Logical Implementation: The code is simple and intuitive, making it easy to understand and maintain. By managing the state of the current Q&A pair and a flag indicating whether an answer is being collected, the process of text segmentation is clearly controlled, ensuring the correct pairing of each Q&A unit.")))}d.isMDXComponent=!0},707:(e,t,n)=>{n.d(t,{Z:()=>i});const i={gradientborder:"gradientborder_cTsr"}}}]);